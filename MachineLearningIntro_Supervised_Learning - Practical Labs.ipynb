{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MachineLearningIntro - Supervised Learning.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a5xDWYHVvuw",
        "colab_type": "text"
      },
      "source": [
        "# Supervised Learning with **PYTHON**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpOzTgrAXdIt",
        "colab_type": "text"
      },
      "source": [
        "**INTRODUCTION**\n",
        "\n",
        "In this practical, we introduce different machine learning algorithms to solve a classification problem. You will create a model for a hospital, to predict if a patient has breast cancer or not \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wik_KXRghGtM",
        "colab_type": "text"
      },
      "source": [
        "In this practical, we tackle the task of classification. Classification in machine learning involves learning a labelling of examples into one (or more) discrete categories. This differs from another common task in machine learning called regression, which involves learning a mapping from inputs to a continuous-valued output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP1eWVSMhu3H",
        "colab_type": "text"
      },
      "source": [
        "#### **Examples of Classification Problems**\n",
        "\n",
        "Determine whether an email message (input) is SPAM or NOT SPAM (label)\n",
        "\n",
        "Determine whether an image, represented by its encoded pixel values (input) is a picture of a DOG or a CAT (label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r10caxbi38U",
        "colab_type": "text"
      },
      "source": [
        "About the Dataset \n",
        "\n",
        "The tagged data set is from the \"Breast Cancer Wisconsin (Diagnostic) Database\" freely available in python's sklearn library, for details see:\n",
        "https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
        "\n",
        "    Number of Samples: 569\n",
        "    Number of Features: 30 numeric, predictive attributes\n",
        "    Number of Classes: 2\n",
        "\n",
        "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. Ten real-valued features are computed for each cell nucleus. The mean, standard error and 'worst' or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. For instance, the radius measurements are for the 'mean radius', 'standard error of the radius', and 'worst radius'. All feature values are recoded with four significant digits.\n",
        "\n",
        "The two target classes correspond to negative outcomes (Benign) and positive outcomes (Malignant).\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1p7Im3aYzof",
        "colab_type": "text"
      },
      "source": [
        "Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SztD4hJjQ6Aw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd # for data manipulation\n",
        "import numpy as np # for mathematical operations\n",
        "import matplotlib.pyplot as plt # for plotting and visualizations\n",
        "import seaborn as sns # for plotting and visualizations\n",
        "\n",
        "# algorithms\n",
        "from sklearn.datasets import load_breast_cancer # for loading the inbuilt dataset\n",
        "from sklearn.linear_model import LogisticRegression as LR # for logistic regression\n",
        "from sklearn.ensemble import RandomForestClassifier as RF # for random forest algorithm\n",
        "from sklearn.ensemble import GradientBoostingClassifier as GBC # for gradient boost\n",
        "from sklearn.naive_bayes import GaussianNB as GNB # for gaussian naive bayes\n",
        "from sklearn import svm # for support vector machine\n",
        "\n",
        "from sklearn.model_selection import train_test_split # for split the data into train and test\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import confusion_matrix # for checking the confusion matrix\n",
        "from sklearn.metrics import precision_recall_curve # for checking the precision and recall curves\n",
        "from sklearn.metrics import roc_curve, auc # for the area under curve and roc metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTa-v_pEaYwS",
        "colab_type": "text"
      },
      "source": [
        "Loading in the data using built in dataset from sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj9JRH0uasKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df = pd.read_csv('/path/to/file.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNQjlhkmR-eF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the dataset\n",
        "Data = load_breast_cancer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVCCcKgYSD2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print a description of the dataset\n",
        "print(Data.DESCR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dgGk0E1SUHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# View the first 5 records of the dataset features\n",
        "df = pd.DataFrame(Data.data, columns = Data.feature_names)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej7kFTnyW_wu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Describe the numerical properties of the data\n",
        "df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6LQQEEOhIiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df.shape\n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pL6ATtyhU-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# information\n",
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZfKyW_UhgvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# missing values\n",
        "df.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiGS3D_7hqde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBnlN3WQY9wD",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### **Describe the Feature Statistics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJmeydmvit0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"The sklearn breast cancer dataset keys:\")\n",
        "print(Data.keys()) # dict_keys(['target_names', 'target', 'feature_names', 'data', 'DESCR'])\n",
        "print(\"---\")\n",
        "\n",
        "# Note that we need to reverse the original '0' and '1' mapping in order to end up with this mapping:\n",
        "# Benign = 0 (negative class)\n",
        "# Malignant = 1 (positive class)\n",
        "\n",
        "li_classes = [Data.target_names[1], Data.target_names[0]]\n",
        "li_target = [1 if x==0 else 0 for x in list(Data.target)]\n",
        "li_ftrs = list(Data.feature_names)\n",
        "\n",
        "print(\"There are 2 target classes:\")\n",
        "print(\"li_classes\", li_classes)\n",
        "print(\"---\")\n",
        "print(\"Target class distribution from a total of %d target values:\" % len(li_target))\n",
        "print(pd.Series(li_target).value_counts())\n",
        "print(\"---\")\n",
        "\n",
        "df_all = pd.DataFrame(Data.data[:,:], columns=li_ftrs)\n",
        "print(\"Describe dataframe, first 6 columns:\")\n",
        "print(df_all.iloc[:,:6].describe().to_string())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTHOxgsilb3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPPGBahjKK9P",
        "colab_type": "text"
      },
      "source": [
        "### **TRAIN/TEST SPLITTING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpYccmvCZHYe",
        "colab_type": "text"
      },
      "source": [
        "Split the data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIJIfuaPKJbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEST_SIZE_RATIO = 0.2   # the training set will be 80% the test set will be 20%\n",
        "# Setup X and y\n",
        "X = df_all\n",
        "y = pd.Series(li_target)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE_RATIO, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3v4GTMFZRPE",
        "colab_type": "text"
      },
      "source": [
        "The labels are y and features are X, since sklearn.model_selection.train_test_split does a random split every time it is called, specifying a random_state value ensures that the split is the same. The split ratio in this case is train:test=80:20 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9QW-5k1lfYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yX = pd.concat([y,X],axis=1) #concatenated data\n",
        "\n",
        "#Rename the first column\n",
        "yX = yX.rename(columns={0: 'TARGET'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvkxXJUcjcc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yX.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saCYaFvbYxqd",
        "colab_type": "text"
      },
      "source": [
        "**CREATE A CORRELATION MATRIX**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ly-EQA4XRID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f, ax = plt.subplots(figsize = (15,10))\n",
        "sns.heatmap(yX.corr().abs(), square=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeIH1IKREwNI",
        "colab_type": "text"
      },
      "source": [
        "#### **Addressing Multicollinearity**\n",
        "Multicollinearity occurs when independent variables in a model are correlated. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_C00cctEyTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# correlation in the df dataset\n",
        "corrmatrix = df.corr().abs()\n",
        "corrmatrix = corrmatrix.stack()\n",
        "corrmatrix[(corrmatrix > 0.6) & (corrmatrix != 0.1).sort_values(ascending = True)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S60LLkfNmIRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# correlation in the yx dataset\n",
        "corrmatrix = yX.corr().abs()\n",
        "corrmatrix = corrmatrix.stack()\n",
        "corrmatrix[(corrmatrix > 0.6) & (corrmatrix != 0.1).sort_values(ascending = True)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwpxt2BWF_j7",
        "colab_type": "text"
      },
      "source": [
        "Note the high correlation between features that are directly related e.g mean radius, mean perimeter, mean area"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J3yic6EzZAx",
        "colab_type": "text"
      },
      "source": [
        "We are going to build our model over several algorithms:\n",
        "\n",
        "- Logistic Regression\n",
        "\n",
        "- Random Forest\n",
        "\n",
        "- Support Vector Machine\n",
        "\n",
        "- Gradient Boosting\n",
        "\n",
        "- Gaussian Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA9suUfmqZdT",
        "colab_type": "text"
      },
      "source": [
        "### **Setup an automatic workflow with pipeline**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wQ8Osbycdbg",
        "colab_type": "text"
      },
      "source": [
        "The use of pipeline will ensure..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtmT148PrKHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNFelzQjrQwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Logistic Regression\n",
        "lr_pipeline = Pipeline([('scaler', StandardScaler()), \n",
        "                        ('classifier', LR(random_state=5))])\n",
        "\n",
        "# Random Forest\n",
        "rf_pipeline = Pipeline([('scaler', StandardScaler()), \n",
        "                        ('classifier', RF(random_state=5))                        \n",
        "])\n",
        "\n",
        "# Gradient Boosting\n",
        "gb_pipeline = Pipeline([('scaler', StandardScaler()), \n",
        "                        ('classifier', GBC())\n",
        "                        ])\n",
        "\n",
        "# Gaussian Naive Bayes\n",
        "nb_pipeline = Pipeline([('scaler', StandardScaler()), \n",
        "                        ('classifier', GNB())])\n",
        "\n",
        "# SVM\n",
        "svm_pipeline = Pipeline([('scaler', StandardScaler()), \n",
        "                        ('classifier', svm.SVC(gamma=0.01, C=100))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI7hJLv6s7Lg",
        "colab_type": "text"
      },
      "source": [
        "**Hyperparameter optimization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpnEPXiktJ1N",
        "colab_type": "text"
      },
      "source": [
        "Using GridSearch and Cross Validation to optimize on model hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-bobk_itVL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#GridSearch for Logistic Regression\n",
        "lr_param_range = [0.001, 0.01, 0.1]\n",
        "lr_class_weight = [{0:0.01, 1:0.99}, {0:0.80, 1:0.20}]\n",
        "lr_param_grid = [{'classifier__C':lr_param_range,\n",
        "                  'classifier__class_weight':lr_class_weight\n",
        "                 }]\n",
        "gridsearch_lr = GridSearchCV(estimator = lr_pipeline,\n",
        "                             param_grid = lr_param_grid,\n",
        "                             n_jobs = -1,\n",
        "                             cv = 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STMvntSxEcJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GridSearch for Random Forest\n",
        "\n",
        "rf_class_weight = [{0:0.01, 1:0.99}, {0:0.10, 1:0.90}, {0:0.80,1:0.20}]\n",
        "rf_param_grid = [\n",
        "                 {'class_weight':rf_class_weight,\n",
        "                  'max_features':[\"auto\", \"sqrt\", \"log2\"],\n",
        "                  'n_estimators': [20, 50],\n",
        "                  'min_samples_leaf': [5, 10],\n",
        "                  'min_samples_split': [100, 200],\n",
        "                  'criterion': [\"entropy\",\"gini\"]\n",
        "                 }\n",
        "                ]\n",
        "rf_classifier = RF()\n",
        "\n",
        "gridsearch_rf = GridSearchCV(\n",
        "                             rf_classifier,\n",
        "                             param_grid = rf_param_grid,\n",
        "                             n_jobs = -1,\n",
        "                             cv = 5,\n",
        "                             refit = True\n",
        "                            )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8gtqsUTFiMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GridSearch for Gradient Boosting Classifier\n",
        "gb_param_grid = [{'classifier__n_estimators': [1000],\n",
        "                  'classifier__max_features': [\"sqrt\"],\n",
        "                  'classifier__min_samples_leaf': [9, 13],\n",
        "                  'classifier__learning_rate': [0.05, 0.01]\n",
        "                }]\n",
        "gridsearch_gb = GridSearchCV(estimator = gb_pipeline,\n",
        "                             param_grid = gb_param_grid,\n",
        "                             n_jobs = -1,\n",
        "                             cv = 2\n",
        "                            )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcY1ZEhqFuy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GridSearch for Support Vector Machine\n",
        "\n",
        "svm_param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
        "svm_param_grid = [{'classifier__C': svm_param_range,\n",
        "                   'classifier__kernel': ['linear']},\n",
        "                  {'classifier__C': svm_param_range,\n",
        "                   'classifier__gamma': svm_param_range,\n",
        "                   'classifier__kernel': ['rbf']}]\n",
        "gridsearch_svm = GridSearchCV(estimator = svm_pipeline,\n",
        "                              param_grid = svm_param_grid,\n",
        "                              n_jobs = -1,\n",
        "                              cv = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7BuxKgjc0Z3",
        "colab_type": "text"
      },
      "source": [
        "We need to know the total number of entries so we can take half of them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a86xE1C5F3pZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yX.info(verbose=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QYa17hnHNYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yX_half = yX[0:280]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vITeZX0adIJ6",
        "colab_type": "text"
      },
      "source": [
        "Extract the features and target that will be used for hyperparameter optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyhHTS1_HiZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_gs_train = yX_half.iloc[:,1:]\n",
        "y_gs_train = yX_half.iloc[:,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMX8V3Inc8Yu",
        "colab_type": "text"
      },
      "source": [
        "Why use dill"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CsOgiQJH2OI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import dill"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gs0Aq1OudZya",
        "colab_type": "text"
      },
      "source": [
        "Fit the dataset to get the hyperparameters and pickle the best_estimator to be used *later*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uasVXb4kIZHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fitting the dataset to get the hyperparameters\n",
        "gridsearch_lr.fit(X_gs_train, y_gs_train)\n",
        "gridsearch_best_estimator_lr = gridsearch_lr.best_estimator_\n",
        "dill.dump(gridsearch_best_estimator_lr, open('LogisticRegression_gridsearch_classweight.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv1HvsNXJhYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gridsearch_rf.fit(X_gs_train, y_gs_train)\n",
        "gridsearch_best_estimator_rf = gridsearch_rf.best_estimator_\n",
        "dill.dump(gridsearch_best_estimator_rf, open('RandomForest_gridsearch_classweight.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojP0TviSOdP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gridsearch_gb.fit(X_gs_train, y_gs_train)\n",
        "gridsearch_best_estimator_gb = gridsearch_gb.best_estimator_\n",
        "dill.dump(gridsearch_best_estimator_gb, open('GradientBoosting_gridsearch_classweight.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lX-2R1CJw69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gridsearch_svm.fit(X_gs_train, y_gs_train)\n",
        "gridsearch_best_estimator_svm = gridsearch_svm.best_estimator_\n",
        "dill.dump(gridsearch_best_estimator_svm, open('SupportVectorMachine_gridsearch_classweight.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A41SB1HzLgby",
        "colab_type": "text"
      },
      "source": [
        "MODEL TRAINING AND EVALUATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfMj7gmmdmNN",
        "colab_type": "text"
      },
      "source": [
        "With the optimized hyperparameters, we can then go ahead and fit models with cross validation. I will also be doing an evaluation of each model for accuracy, precision, recall, as well as the area under the Receiver Operating Characteristic (ROC) curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCDg0KM2L6AE",
        "colab_type": "text"
      },
      "source": [
        "Importing packages for model selection and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj-wA0GuMFoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import plot_roc_curve\n",
        "from scipy import interp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHH5UbrKLojs",
        "colab_type": "text"
      },
      "source": [
        "Function to draw a confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2ZJX4k2KCUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_confusion_matrix(conf_matrix, classifier_name):\n",
        "    fig, ax = plt.subplots(figsize = (5,5))\n",
        "    ax.matshow(conf_matrix, cmap = plt.cm.Greens, alpha=0.3)\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "         for j in range(conf_matrix.shape[1]):\n",
        "                 ax.text(x=j, y=i, s=conf_matrix[i, j], va = 'center', ha = 'center')\n",
        "    plt.title('Confusion Matrix for %s' % classifier_name)\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.ylabel('True')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou_am3XXMYaY",
        "colab_type": "text"
      },
      "source": [
        "Cross Validation function\n",
        "\n",
        "In the run_cv function, I will apply the cross-validation as well as draw the ROC curves for each training-validation fold.\n",
        "Area Under Curve (AUC) plots are independent of the fraction of each class and are therefore a very good metric for evaluating a classifier performance in the case of when you are dealing with an imbalanced data set such as this one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ET1BdmgMcKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_cv(X, Y, classifier, clf_name):\n",
        "    \n",
        "    #Construct a kfolds object\n",
        "    kf = StratifiedKFold(n_splits=5,shuffle=True)\n",
        "\n",
        "    \n",
        "    accuracy_scores = []\n",
        "            \n",
        "    #Initialize ROC variables\n",
        "    tprs = []\n",
        "    aucs = []\n",
        "    mean_fpr = np.linspace(0, 1, 100)\n",
        "    \n",
        "    \n",
        "    clf = classifier\n",
        "    \n",
        "    y_pred_full = Y.copy()\n",
        "    \n",
        "    fig, ax = plt.subplots()\n",
        "    \n",
        "    #Iterate through folds\n",
        "    for i, (train_index, test_index) in enumerate(kf.split(X,Y)):\n",
        "        \n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        Y_train = Y.iloc[train_index]\n",
        "        Y_test = Y.iloc[test_index]\n",
        "            \n",
        "     #Train the classifier on the training data\n",
        "        clf_fit = clf.fit(X_train,Y_train)\n",
        "          \n",
        "         #Get probabilities and compute area under ROC curve\n",
        "        viz = plot_roc_curve(clf, X_test, Y_test, name = 'ROC fold {}'.format(i), alpha=0.3, lw = 1, ax = ax)            \n",
        "        interp_tpr = interp(mean_fpr, viz.fpr, viz.tpr)\n",
        "        interp_tpr[0] = 0.0\n",
        "        tprs.append(interp_tpr)\n",
        "        aucs.append(viz.roc_auc)\n",
        "        \n",
        "        #Obtain a prediction on the test set\n",
        "        y_pred = clf_fit.predict(X_test)\n",
        "        \n",
        "        #Map the prediction for this fold to the full dataset\n",
        "        y_pred_full.iloc[test_index] = y_pred\n",
        "    \n",
        "        #Calculate the accuracy of the prediction on current fold\n",
        "        accuracy_scores.append(accuracy_score(y_true=Y_test, y_pred=y_pred))\n",
        "        \n",
        "        \n",
        "        \n",
        "    \n",
        "    #Get Evaluation metrics    \n",
        "    #Draw ROC Curve    \n",
        "    mean_tpr = np.mean(tprs, axis = 0)\n",
        "    mean_tpr[-1] = 1.0\n",
        "    mean_auc = auc(mean_fpr, mean_tpr)\n",
        "    std_auc = np.std(aucs)\n",
        "    \n",
        "    \n",
        "    ax.plot([0, 1], \n",
        "             [0, 1], \n",
        "             '--', \n",
        "             color=(0.6, 0.6, 0.6), \n",
        "             label='Luck',\n",
        "             alpha =.8\n",
        "            )\n",
        "    \n",
        "    ax.plot([0, 0, 1], \n",
        "             [0, 1, 1], \n",
        "             lw=2,\n",
        "             linestyle=':',\n",
        "             color='black',\n",
        "             label='Perfect Performance')\n",
        "    \n",
        "    ax.plot(mean_fpr, \n",
        "             mean_tpr, \n",
        "             'k--',\n",
        "             label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc), lw=2, alpha=.8)\n",
        "    \n",
        "#     std_tpr = np.std(tprs, axis = 0)\n",
        "#     tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
        "#     tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
        "#     ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color = 'grey', alpha =.2, label = r'$\\pm$ 1 std. dev.')\n",
        "    \n",
        "    plt.xlim([-0.05, 1.05])\n",
        "    plt.ylim([-0.05, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic for %s' % classifier_name)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    #plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    #Accuracy score\n",
        "    mean = np.mean(accuracy_scores)\n",
        "    std = np.std(accuracy_scores)\n",
        "    print (clf_name + ':' + '\\n' + 'cross-validation accuracy')\n",
        "    print (\"%.2f +/- %.3f\" % (mean, std))\n",
        "    print (classification_report(Y, y_pred_full))\n",
        "    \n",
        "    #Confusion Matrix\n",
        "    conf_matrix = confusion_matrix(y_true=Y, y_pred=y_pred_full)\n",
        "    draw_confusion_matrix(conf_matrix, clf_name)\n",
        "    \n",
        "    return clf_fit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yAGv1svM6E7",
        "colab_type": "text"
      },
      "source": [
        "Getting the previously pickled files for each algorithm and running cross validation on each algorithm for comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25nb3IwjMtv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LR\n",
        "with open('LogisticRegression_gridsearch_classweight.pkl', 'rb') as f:\n",
        "    LogisticRegression_classifier = dill.load(f)\n",
        "classifier_name = 'Logistic Regression Classifier'\n",
        "model_pipeline_lr = run_cv(X_train, y_train, LogisticRegression_classifier, classifier_name)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGXUTMkXNdWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gradient Boosting Classifier\n",
        "with open('GradientBoosting_gridsearch_classweight.pkl', 'rb') as f:\n",
        "    GradientBoosting_classifier = dill.load(f)\n",
        "classifier_name = 'Gradient Boosting'\n",
        "model_pipeline_gb = run_cv(X_train, y_train, GradientBoosting_classifier, classifier_name)\n",
        "dill.dump(model_pipeline_gb, open('GradientBoosting_model_AllFeatures.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFyTpGZ2ODQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Random Forest Classifier\n",
        "\n",
        "with open('RandomForest_gridsearch_classweight.pkl', 'rb') as f:\n",
        "    RandomForest_classifier = dill.load(f)\n",
        "classifier_name = 'Random Forest'\n",
        "model_pipeline_rf = run_cv(X_train, y_train, RandomForest_classifier, classifier_name)\n",
        "dill.dump(model_pipeline_rf,open('RandomForest_model_AllFeatures.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbwrCO-qQhVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Gaussian Naive Bayes\n",
        "\n",
        "classifier_name = 'Gaussian Naive Bayes'\n",
        "GaussianNB_classifier = GNB()\n",
        "model_pipeline_gnb = run_cv(X_train, y_train, GaussianNB_classifier, classifier_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sA0kJpPQxxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('SupportVectorMachine_gridsearch_classweight.pkl', 'rb') as f:\n",
        "    SupportVectorMachine_classifier = dill.load(f)\n",
        "classifier_name = 'Support Vector Machine'\n",
        "model_pipeline_svm = run_cv(X_train, y_train, SupportVectorMachine_classifier, classifier_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJLVkq8OSq2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}